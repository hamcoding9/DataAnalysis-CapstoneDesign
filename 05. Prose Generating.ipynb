{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05. Prose Generating.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 시 생성"
      ],
      "metadata": {
        "id": "4I4IUVZ5vFDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0lMnnA3AvCnk"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "\n",
        "def load_model(model_path):\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "    return model\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n",
        "    return tokenizer\n",
        "\n",
        "def generate_text(sequence, max_length):\n",
        "    model_path = '/content/drive/MyDrive/capstone/sk_checkpoint(0610)'\n",
        "    model = load_model(model_path)\n",
        "    tokenizer = load_tokenizer(model_path)\n",
        "    ids = tokenizer.encode(f'{sequence}', return_tensors = 'pt')\n",
        "    final_outputs = model.generate(\n",
        "        ids,\n",
        "        do_sample = True,\n",
        "        max_length = max_length,\n",
        "        pad_token_id = model.config.pad_token_id,\n",
        "        top_k = 80,\n",
        "        top_p = 0.95\n",
        "    )\n",
        "    text = tokenizer.decode(final_outputs[0], skip_special_tokens = True)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prose(input, line, max_len):\n",
        "    prose = \"\"\n",
        "    for i in range(line):\n",
        "        input = \"</s>\" + input + \"</s>\"\n",
        "        prose = generate_text(input, max_len)\n",
        "        input = prose\n",
        "    print(prose)"
      ],
      "metadata": {
        "id": "QV9mPY31vrab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = '나는 맨발로 계단을 오른다.'\n",
        "make_prose(input, 5, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Jjd6PvvrXt",
        "outputId": "08313cdc-e2af-4fcb-bbf0-ee01a2659192"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나는 맨발로 계단을 오른다. 맨발로 계단을 올라간다. 내가 맨발로 뛰어내린 것은 너를 지키기 위해서이다. 맨발로 뛰어내린 그 순간부터 나는 너를 위해 살고 있다. 맨발로 계단을 올랐을 때 내가 내 신발을 신고 있는 것을 깨닫지 못하는 것은 너를 지키기 위함이라는 것을. 맨발로 뛰어내린 너에게 나는 감사함을 느낀다.\n"
          ]
        }
      ]
    }
  ]
}